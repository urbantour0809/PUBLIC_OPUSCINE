import json
import re
import torch
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import os
from transformers import AutoModelForCausalLM, AutoTokenizer

class MovieRecommendationLLM:
    """
    EXAONE 3.5-7.8B ëª¨ë¸ì„ ì‚¬ìš©í•œ ì˜í™” ì¶”ì²œ ìì—°ì–´ ì²˜ë¦¬ í´ë˜ìŠ¤
    """
    
    def __init__(self, model_name: str = "LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct"):
        self.model_name = model_name
        self.model = None
        self.tokenizer = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # ëª¨ë¸ ë¡œë”© ì‹œë„
        self._load_model()
        
        # TMDB ì¥ë¥´ ë§¤í•‘
        self.genre_mapping = {
            # í•œêµ­ì–´ -> TMDB ì¥ë¥´ ID
            "ì•¡ì…˜": 28, "ëª¨í—˜": 12, "ì• ë‹ˆë©”ì´ì…˜": 16, "ì½”ë¯¸ë””": 35,
            "ë²”ì£„": 80, "ë‹¤íë©˜í„°ë¦¬": 99, "ë“œë¼ë§ˆ": 18, "ê°€ì¡±": 10751,
            "íŒíƒ€ì§€": 14, "ì—­ì‚¬": 36, "ê³µí¬": 27, "ìŒì•…": 10402,
            "ë¯¸ìŠ¤í„°ë¦¬": 9648, "ë¡œë§¨ìŠ¤": 10749, "SF": 878, "ê³¼í•™ì†Œì„¤": 878,
            "TVì˜í™”": 10770, "ìŠ¤ë¦´ëŸ¬": 53, "ì „ìŸ": 10752, "ì„œë¶€": 37,
            "ëŠì™€ë¥´": 80, "ë©œë¡œ": 10749, "ë®¤ì§€ì»¬": 10402
        }
        
        # ìœ ëª… ê°ë… ID ë§¤í•‘
        self.director_mapping = {
            "ë´‰ì¤€í˜¸": 21684, "ë°•ì°¬ìš±": 13153, "ê¹€ê¸°ë•": 13154,
            "ì´ì°½ë™": 17698, "í™ìƒìˆ˜": 13155, "ì„ê¶Œíƒ": 13156,
            "í¬ë¦¬ìŠ¤í† í¼ ë†€ë€": 525, "ìŠ¤í‹°ë¸ ìŠ¤í•„ë²„ê·¸": 488,
            "ë§ˆí‹´ ìŠ¤ì½”ì„¸ì§€": 1032, "ì¿ ì—”í‹´ íƒ€ë€í‹°ë…¸": 138
        }
        
    def _load_model(self):
        """EXAONE ëª¨ë¸ ë¡œë”©"""
        try:
            print(f"ğŸ¤– EXAONE ëª¨ë¸ ë¡œë”© ì¤‘... ({self.model_name})")
            
            # ëª¨ë¸ ë¡œë”©
            self.model = AutoModelForCausalLM.from_pretrained(
                self.model_name,
                torch_dtype=torch.bfloat16,
                trust_remote_code=True,
                device_map="auto" if torch.cuda.is_available() else None
            )
            
            # í† í¬ë‚˜ì´ì € ë¡œë”©
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            
            print(f"âœ… EXAONE ëª¨ë¸ ë¡œë”© ì™„ë£Œ (ë””ë°”ì´ìŠ¤: {self.device})")
            
        except Exception as e:
            print(f"âŒ EXAONE ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            print("âš ï¸  ê·œì¹™ ê¸°ë°˜ íŒŒì‹±ìœ¼ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤.")
            self.model = None
            self.tokenizer = None
    
    def _create_movie_prompt(self, user_message: str) -> str:
        """ì˜í™” ì¶”ì²œìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        system_prompt = """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ í•œêµ­ì–´ ì˜í™” ì¶”ì²œ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ TMDB API ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ AIì…ë‹ˆë‹¤.

ë‹¤ìŒ ê·œì¹™ì„ ë”°ë¼ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:

1. ì¥ë¥´ ë§¤í•‘:
   - ì•¡ì…˜: 28, ëª¨í—˜: 12, ì• ë‹ˆë©”ì´ì…˜: 16, ì½”ë¯¸ë””: 35
   - ë²”ì£„: 80, ë‹¤íë©˜í„°ë¦¬: 99, ë“œë¼ë§ˆ: 18, ê°€ì¡±: 10751
   - íŒíƒ€ì§€: 14, ì—­ì‚¬: 36, ê³µí¬: 27, ìŒì•…: 10402
   - ë¯¸ìŠ¤í„°ë¦¬: 9648, ë¡œë§¨ìŠ¤: 10749, SF: 878, ìŠ¤ë¦´ëŸ¬: 53

2. ê°ë… ë§¤í•‘:
   - ë´‰ì¤€í˜¸: 21684, ë°•ì°¬ìš±: 13153, ì´ì°½ë™: 17698
   - í¬ë¦¬ìŠ¤í† í¼ ë†€ë€: 525, ìŠ¤í‹°ë¸ ìŠ¤í•„ë²„ê·¸: 488

3. ì¶œë ¥ í˜•ì‹ (JSONë§Œ):
{
  "with_genres": [ì¥ë¥´IDë°°ì—´],
  "primary_release_date.gte": "YYYY-MM-DD",
  "primary_release_date.lte": "YYYY-MM-DD",
  "with_people": [ì¸ë¬¼IDë°°ì—´],
  "sort_by": "ì •ë ¬ë°©ì‹",
  "language": "ko-KR",
  "vote_average.gte": í‰ì ìµœì†Œê°’
}

4. íŠ¹ë³„ ì²˜ë¦¬:
   - "ìµœì‹ ", "ìµœê·¼" â†’ ìµœê·¼ 2ë…„ ë²”ìœ„
   - "ê³ ì „", "ì˜¤ë˜ëœ" â†’ 2000ë…„ ì´ì „
   - "ëª…ì‘", "ê±¸ì‘" â†’ vote_average.gte: 7.0
   - "í•œêµ­ì˜í™”" â†’ with_origin_country: ["KR"]"""

        return f"{system_prompt}\n\nì‚¬ìš©ì ìš”ì²­: {user_message}\n\nJSON ì‘ë‹µ:"
    
    def parse_movie_request(self, user_message: str) -> Dict[str, Any]:
        """
        ì‚¬ìš©ìì˜ ìì—°ì–´ ìš”ì²­ì„ TMDB API íŒŒë¼ë¯¸í„°ë¡œ ë³€í™˜
        """
        try:
            if self.model and self.tokenizer:
                # EXAONE ëª¨ë¸ ì‚¬ìš©
                return self._exaone_parsing(user_message)
            else:
                # ê·œì¹™ ê¸°ë°˜ íŒŒì‹± (ë°±ì—…)
                return self._rule_based_parsing(user_message)
                
        except Exception as e:
            print(f"âš ï¸  ëª¨ë¸ íŒŒì‹± ì‹¤íŒ¨, ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì²´: {e}")
            return self._rule_based_parsing(user_message)
    
    def _exaone_parsing(self, user_message: str) -> Dict[str, Any]:
        """
        EXAONE ëª¨ë¸ì„ ì‚¬ìš©í•œ ìì—°ì–´ íŒŒì‹±
        """
        try:
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_movie_prompt(user_message)
            
            # ë©”ì‹œì§€ í¬ë§·
            messages = [
                {"role": "system", 
                 "content": "You are EXAONE model from LG AI Research, a helpful assistant specialized in movie recommendations."},
                {"role": "user", "content": prompt}
            ]
            
            # í† í¬ë‚˜ì´ì§•
            input_ids = self.tokenizer.apply_chat_template(
                messages,
                tokenize=True,
                add_generation_prompt=True,
                return_tensors="pt"
            )
            
            # GPUë¡œ ì´ë™
            if self.device == "cuda":
                input_ids = input_ids.to("cuda")
            
            # ìƒì„±
            with torch.no_grad():
                output = self.model.generate(
                    input_ids,
                    eos_token_id=self.tokenizer.eos_token_id,
                    max_new_tokens=512,
                    do_sample=False,
                    temperature=0.1,
                    pad_token_id=self.tokenizer.eos_token_id
                )
            
            # ë””ì½”ë”©
            response = self.tokenizer.decode(output[0], skip_special_tokens=True)
            
            # JSON ì¶”ì¶œ
            json_start = response.find("{")
            json_end = response.rfind("}") + 1
            
            if json_start != -1 and json_end > json_start:
                json_str = response[json_start:json_end]
                parameters = json.loads(json_str)
                
                return {
                    "parameters": parameters,
                    "confidence": 0.95,
                    "original_message": user_message,
                    "method": "exaone_model"
                }
            else:
                raise Exception("JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                
        except Exception as e:
            print(f"EXAONE íŒŒì‹± ì˜¤ë¥˜: {e}")
            raise e
    
    def _rule_based_parsing(self, user_message: str) -> Dict[str, Any]:
        """
        ê·œì¹™ ê¸°ë°˜ íŒŒì‹± (ë°±ì—…ìš©)
        """
        message = user_message.lower().strip()
        params = {
            "language": "ko-KR",
            "sort_by": "popularity.desc"
        }
        
        # ì¥ë¥´ ì¶”ì¶œ
        genres = []
        for korean_genre, genre_id in self.genre_mapping.items():
            if korean_genre in message:
                genres.append(genre_id)
        if genres:
            params["with_genres"] = genres
        
        # ì—°ë„ ì¶”ì¶œ
        year_pattern = r'(\d{4})ë…„?'
        year_matches = re.findall(year_pattern, message)
        if year_matches:
            year = year_matches[-1]
            params["primary_release_date.gte"] = f"{year}-01-01"
            params["primary_release_date.lte"] = f"{year}-12-31"
        
        # ìµœì‹ /ìµœê·¼ ì˜í™”
        if any(word in message for word in ["ìµœì‹ ", "ìµœê·¼", "ìƒˆë¡œìš´", "ì‹ ì‘"]):
            current_year = datetime.now().year
            params["primary_release_date.gte"] = f"{current_year-1}-01-01"
        
        # ì˜¤ë˜ëœ ì˜í™”
        if any(word in message for word in ["ì˜¤ë˜ëœ", "ê³ ì „", "ì˜›ë‚ "]):
            params["primary_release_date.lte"] = "2000-12-31"
        
        # ê°ë… ì¶”ì¶œ
        directors = []
        for director_name, director_id in self.director_mapping.items():
            if director_name in message:
                directors.append(director_id)
        if directors:
            params["with_people"] = directors
        
        # í‰ì  ê´€ë ¨
        if any(word in message for word in ["ëª…ì‘", "ê±¸ì‘", "í‰ì ë†’ì€", "ì¢‹ì€"]):
            params["vote_average.gte"] = 7.0
        elif any(word in message for word in ["í‰ì ë‚®ì€", "ë³„ë¡œì¸"]):
            params["vote_average.lte"] = 5.0
        
        # ì •ë ¬ ë°©ì‹
        if any(word in message for word in ["ì¸ê¸°", "ì¸ê¸°ìˆëŠ”"]):
            params["sort_by"] = "popularity.desc"
        elif any(word in message for word in ["í‰ì ", "í‰ì ìˆœ"]):
            params["sort_by"] = "vote_average.desc"
        elif any(word in message for word in ["ìµœì‹ ìˆœ", "ê°œë´‰ìˆœ"]):
            params["sort_by"] = "release_date.desc"
        
        return {
            "parameters": params,
            "confidence": 0.75,
            "original_message": user_message,
            "method": "rule_based"
        }
    
    def is_model_loaded(self) -> bool:
        """ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸"""
        return self.model is not None and self.tokenizer is not None
    
    def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            "model_name": self.model_name,
            "device": self.device,
            "loaded": self.is_model_loaded(),
            "cuda_available": torch.cuda.is_available(),
            "gpu_count": torch.cuda.device_count() if torch.cuda.is_available() else 0
        } 